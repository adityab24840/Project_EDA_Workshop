{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48vAXjSNQSI3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.dates as dates\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (6.0, 4.0) # set default size of plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYX1T_zSVIvI"
      },
      "outputs": [],
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/OddSem2023MAHE'\n",
        "    DATA_DIR = DIR + '/Data/'\n",
        "    os.chdir(DIR)\n",
        "else:\n",
        "    DATA_DIR = 'Data/' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzPfv_CVyDpq"
      },
      "outputs": [],
      "source": [
        "## Read data\n",
        "FILE = DATA_DIR + 'timeseriesdata.csv'\n",
        "df = pd.read_csv(FILE, sep = \",\", header = 0)\n",
        "df['time'] = pd.to_datetime(df['time'], format='%m-%d-%Y %H.%M')\n",
        "df.loc[:, (df.columns != 'time')] = df.loc[:, df.columns != 'time'].apply(pd.to_numeric, errors = 'coerce')\n",
        "df = df.set_index('time')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi5aIXFAgAZ9"
      },
      "outputs": [],
      "source": [
        "## Plot percentage of missing values (NaNs) for each feature\n",
        "cutoff = 30\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "percent_missing = (df.isna().sum() / df.shape[0]) * 100\n",
        "percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n",
        "plt.plot(np.arange(df.shape[1]), np.repeat(cutoff, df.shape[1]), 'g--')\n",
        "fig.suptitle('Percentage Missing Values Across All Features', fontsize = 20)\n",
        "plt.xlabel('Feature', fontsize = 16)\n",
        "plt.ylabel('% Missing Values', fontsize = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX12wcB4QSI-"
      },
      "outputs": [],
      "source": [
        "## Linear interpolation for one column\n",
        "#df['Cyclone_Inlet_Gas_Temp'] = df['Cyclone_Inlet_Gas_Temp'].interpolate(method = 'linear')\n",
        "df.loc[:, (df.columns != 'time')] = df.loc[:, df.columns != 'time'].interpolate(method = 'linear')\n",
        "(df.isna().sum() / df.shape[0]) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRZx0gkDKtLg"
      },
      "outputs": [],
      "source": [
        "## Data preparation for anomaly detection using numpy\n",
        "feature = 'Cyclone_Inlet_Gas_Temp'\n",
        "# Note that 5min is the sampling period in the dataset which we specify and convert to seconds\n",
        "sampling_period = int(pd.Timedelta('5min').total_seconds())\n",
        "# We are interested in 30min data for each sample which we specify and convert to seconds\n",
        "time_period = int(pd.Timedelta('30min').total_seconds())\n",
        "# The following is a dictionary that we will use for transforming the columns\n",
        "# 'identity' corresponds to no transformation, 'standard' means standardizing\n",
        "scaler = {'identity': FunctionTransformer(lambda x: x), 'standard': StandardScaler()}\n",
        "df_transformed = pd.DataFrame(scaler['standard'].fit_transform(df))\n",
        "df_transformed.columns = df.columns.copy()\n",
        "df_transformed.index = df.index.copy()\n",
        "ncols_reshape = int(pd.Timedelta(str(time_period/sampling_period)+'S').total_seconds())\n",
        "nrows_reshape = df_transformed.shape[0]//ncols_reshape\n",
        "df_samples = pd.DataFrame(np.array(df_transformed[feature])[0:nrows_reshape*ncols_reshape].reshape(nrows_reshape, ncols_reshape))\n",
        "df_samples.index = pd.date_range(df_transformed.index.min(),\n",
        "                                 df_transformed.index.max() + pd.DateOffset(days = 1),\n",
        "                                 normalize = True,\n",
        "                                 freq = str(time_period)+'S')[0:df_samples.shape[0]]\n",
        "df_samples.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVMSss1ge5iz"
      },
      "outputs": [],
      "source": [
        "## Data preparation for anomaly detection using pandas groupby()\n",
        "feature = 'Cyclone_Inlet_Gas_Temp'\n",
        "# Note that 5min is the sampling period in the dataset which we specify and convert to seconds\n",
        "sampling_period = int(pd.Timedelta('5min').total_seconds())\n",
        "# We are interested in 30min data for each sample which we specify and convert to seconds\n",
        "time_period = int(pd.Timedelta('30min').total_seconds())\n",
        "# The following is a dictionary that we will use for transforming the columns\n",
        "# 'identity' corresponds to no transformation, 'standard' means standardizing\n",
        "scaler = {'identity': FunctionTransformer(lambda x: x), 'standard': StandardScaler()}\n",
        "df_transformed = pd.DataFrame(scaler['standard'].fit_transform(df))\n",
        "df_transformed.columns = df.columns.copy()\n",
        "df_transformed.index = df.index.copy()\n",
        "df_samples = df_transformed.groupby(pd.Grouper(freq = str(time_period)+'S')).apply(lambda x: x[feature].values if len(x[feature].values) == int(pd.Timedelta(str(time_period/sampling_period)+'S').total_seconds()) else np.nan)\n",
        "df_samples = df_samples.dropna()\n",
        "df_samples = pd.DataFrame(df_samples.values.tolist(), index = df_samples.index)\n",
        "df_samples.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "854f9ff9f945bab8ba5d04e939504df285fc62eb45b7a687b185fca2375459b7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
